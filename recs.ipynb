{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b384004",
   "metadata": {
    "id": "2b384004"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from itertools import chain\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD, SVDpp, NMF\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.dump import dump\n",
    "\n",
    "from re import U\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo.operations import ReplaceOne\n",
    "import requests\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import pymongo\n",
    "from pymongo import UpdateOne, ReplaceOne\n",
    "from pymongo.errors import BulkWriteError\n",
    "\n",
    "import datetime\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628d8473",
   "metadata": {
    "id": "628d8473"
   },
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(recs, test):\n",
    "    \"\"\"\n",
    "    Compute the Mean Reciprocal Rank (MRR).\n",
    "\n",
    "    Parameters:\n",
    "        recs (list): List of tuples (movie_id, score) in ranked order.\n",
    "        test (list): List of tuples (movie_id, rating).\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Reciprocal Rank (MRR).\n",
    "    \"\"\"\n",
    "    test_ids = {movie_id for movie_id, _ in test}\n",
    "    for rank, (movie_id, _) in enumerate(recs, start=1):\n",
    "        if movie_id in test_ids:\n",
    "            return 1 / rank\n",
    "    return 0  # No relevant items found in the recommendations\n",
    "\n",
    "def ndcg(recs, test):\n",
    "    \"\"\"\n",
    "    Compute the Normalized Discounted Cumulative Gain (nDCG).\n",
    "\n",
    "    Parameters:\n",
    "        recs (list): List of tuples (movie_id, score) in ranked order.\n",
    "        test (list): List of tuples (movie_id, rating).\n",
    "\n",
    "    Returns:\n",
    "        float: Normalized Discounted Cumulative Gain (nDCG).\n",
    "    \"\"\"\n",
    "    test_ratings = dict(test)\n",
    "\n",
    "    # Compute DCG\n",
    "    dcg = sum(test_ratings.get(movie_id, 0) / np.log2(rank + 1) for rank, (movie_id, _) in enumerate(recs, start=1))\n",
    "\n",
    "    # Compute Ideal DCG\n",
    "    ideal_ranking = sorted(test_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    idcg = sum(rating / np.log2(rank + 1) for rank, (movie_id, rating) in enumerate(ideal_ranking, start=1))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def precision_at_k(recs, test, k=50):\n",
    "    \"\"\"\n",
    "    Compute Precision at k (P@k).\n",
    "\n",
    "    Parameters:\n",
    "        recs (list): List of tuples (movie_id, score) in ranked order.\n",
    "        test (list): List of tuples (movie_id, rating).\n",
    "        k (int): The number of top recommendations to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: Precision at k.\n",
    "    \"\"\"\n",
    "    test_ids = {movie_id for movie_id, _ in test}\n",
    "    top_k_recs = recs[:k]\n",
    "    hits = len([movie_id for movie_id, _ in top_k_recs if movie_id in test_ids])\n",
    "    return hits / k if k > 0 else 0\n",
    "\n",
    "def compute_metrics(recs, test, k=10):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "        recs (list): List of tuples (movie_id, score) in ranked order.\n",
    "        test (list): List of tuples (movie_id, rating).\n",
    "        k (int): The number of top recommendations to consider for P@k.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of computed metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    metrics['precision_at_k'] = precision_at_k(recs, test, k=k)\n",
    "    metrics['mean_reciprocal_rank'] = mean_reciprocal_rank(recs, test)\n",
    "    metrics['ndcg'] = ndcg(recs, test)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fadaf67",
   "metadata": {
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1732734465081,
     "user": {
      "displayName": "Sierra Eva Martinez-Kratz",
      "userId": "11773033365985257755"
     },
     "user_tz": 300
    },
    "id": "7fadaf67"
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movie_data.csv', quotechar='\"', escapechar=\"\\\\\", on_bad_lines='skip', engine=\"python\")\n",
    "users = pd.read_csv('users_export.csv')\n",
    "ratings = pd.read_csv('training_data.csv', nrows=1000000)\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7070eafe",
   "metadata": {
    "executionInfo": {
     "elapsed": 19562,
     "status": "ok",
     "timestamp": 1732734896616,
     "user": {
      "displayName": "Sierra Eva Martinez-Kratz",
      "userId": "11773033365985257755"
     },
     "user_tz": 300
    },
    "id": "7070eafe"
   },
   "outputs": [],
   "source": [
    "def create_movie_data_sample(movies, movie_list):\n",
    "    movie_df = movies[movies[\"movie_id\"].isin(movie_list)].copy()\n",
    "    movie_df = movie_df[[\"movie_id\", \"image_url\", \"movie_title\", \"year_released\"]]\n",
    "    movie_df[\"image_url\"] = (\n",
    "        movie_df[\"image_url\"]\n",
    "        .fillna(\"\")\n",
    "        .str.replace(\"https://a.ltrbxd.com/resized/\", \"\", regex=False)\n",
    "    )\n",
    "    movie_df[\"image_url\"] = (\n",
    "        movie_df[\"image_url\"]\n",
    "        .fillna(\"\")\n",
    "        .str.replace(\n",
    "            \"https://s.ltrbxd.com/static/img/empty-poster-230.c6baa486.png\",\n",
    "            \"\",\n",
    "            regex=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return movie_df\n",
    "\n",
    "# Generate training data sample\n",
    "training_df = ratings.copy()\n",
    "\n",
    "review_counts_df = (\n",
    "    ratings.groupby(\"movie_id\")\n",
    "    .size()  # Count reviews per movie\n",
    "    .reset_index(name=\"count\")  # Rename the count column\n",
    ")\n",
    "\n",
    "threshold_movie_list = review_counts_df[\"movie_id\"].to_list()\n",
    "\n",
    "# Generate movie data CSV\n",
    "movie_df = create_movie_data_sample(movies, threshold_movie_list)\n",
    "\n",
    "# Use movie_df to remove any items from threshold_list that do not have a \"year_released\"\n",
    "# This virtually always means it's a collection of more popular movies (such as the LOTR trilogy) and we don't want it included in recs\n",
    "retain_list = movie_df.loc[\n",
    "    (movie_df[\"year_released\"].notna() & movie_df[\"year_released\"] != 0.0)\n",
    "][\"movie_id\"].to_list()\n",
    "\n",
    "threshold_movie_list = [x for x in threshold_movie_list if x in retain_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99c28a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1732735022248,
     "user": {
      "displayName": "Sierra Eva Martinez-Kratz",
      "userId": "11773033365985257755"
     },
     "user_tz": 300
    },
    "id": "c99c28a1",
    "outputId": "9c8f84b6-98db-4321-bd50-335305e19632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nuser_data, status = await get_user_data(\\'geraldne\\')\\n\\nif status == \"success\":\\n    user_data_train, user_data_test = train_test_split(\\n                user_data, test_size=0.2, random_state=42, stratify=[val == -1 for val in rating_vals])\\n    algo, user_watched_list, bpr_data = build_model(df, user_data_train, model=\\'BPR\\')\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def fetch(url, session, input_data={}):\n",
    "    async with session.get(url) as response:\n",
    "        try:\n",
    "            return await response.read(), input_data\n",
    "        except:\n",
    "            return None, None\n",
    "\n",
    "async def generate_ratings_operations(response, send_to_db=True, return_unrated=False):\n",
    "    # Parse ratings page response for each rating/review, use lxml parser for speed\n",
    "    soup = BeautifulSoup(response[0], \"lxml\")\n",
    "    reviews = soup.findAll(\"li\", attrs={\"class\": \"poster-container\"})\n",
    "\n",
    "    # Create empty array to store list of bulk operations or rating objects\n",
    "    ratings_operations = []\n",
    "    movie_operations = []\n",
    "\n",
    "    for review in reviews:\n",
    "        movie_id = review.find(\"div\", attrs={\"class\", \"film-poster\"})[\n",
    "            \"data-target-link\"\n",
    "        ].split(\"/\")[-2]\n",
    "\n",
    "        # Check for rating\n",
    "        rating = review.find(\"span\", attrs={\"class\": \"rating\"})\n",
    "        if not rating:\n",
    "            if not return_unrated:\n",
    "                continue\n",
    "            rating_val = -1\n",
    "        else:\n",
    "            rating_class = rating[\"class\"][-1]\n",
    "            rating_val = int(rating_class.split(\"-\")[-1])\n",
    "\n",
    "        rating_object = {\n",
    "            \"movie_id\": movie_id,\n",
    "            \"rating_val\": rating_val,\n",
    "            \"user_id\": response[1][\"username\"],\n",
    "        }\n",
    "\n",
    "        if not send_to_db:\n",
    "            ratings_operations.append(rating_object)\n",
    "        else:\n",
    "            # Add UpdateOne operations for database insertion\n",
    "            ratings_operations.append(\n",
    "                UpdateOne(\n",
    "                    {\"user_id\": response[1][\"username\"], \"movie_id\": movie_id},\n",
    "                    {\"$set\": rating_object},\n",
    "                    upsert=True,\n",
    "                )\n",
    "            )\n",
    "            movie_operations.append(\n",
    "                UpdateOne(\n",
    "                    {\"movie_id\": movie_id},\n",
    "                    {\"$set\": {\"movie_id\": movie_id}},\n",
    "                    upsert=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return ratings_operations, movie_operations\n",
    "\n",
    "def build_model(df, user_data, model='SVD', num_factors=10, learning_rate=0.01, regularization=0.05, iterations=100):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from implicit.bpr import BayesianPersonalizedRanking\n",
    "\n",
    "    # Set random seed\n",
    "    random.seed(12)\n",
    "    np.random.seed(12)\n",
    "\n",
    "    # Filter user_data based on the model type\n",
    "    if model == 'BPR':\n",
    "        # Include both rated items and likes for BPR\n",
    "        user_data_filtered = user_data\n",
    "    else:\n",
    "        # Exclude likes for SVD and NMF\n",
    "        user_data_filtered = [x for x in user_data if x['rating_val'] > 0]\n",
    "\n",
    "    # Convert filtered user_data to a DataFrame and append it to the existing data\n",
    "    user_df = pd.DataFrame(user_data_filtered)\n",
    "    df = pd.concat([df, user_df]).reset_index(drop=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    if model == 'BPR':\n",
    "        # Add likes to dataset\n",
    "        likes = pd.read_csv('likes.csv', quotechar='\"', escapechar=\"\\\\\", on_bad_lines='skip', engine=\"python\")\n",
    "        likes['rating_val'] = -1\n",
    "        df = pd.concat([df, likes[['movie_id', 'user_id', 'rating_val']]], ignore_index=True)\n",
    "        df = df.drop_duplicates(subset=['movie_id', 'user_id'], ignore_index=True)\n",
    "\n",
    "        # Filter movies with few interactions\n",
    "        movie_threshold = 5\n",
    "        df = df[df['movie_id'].isin(df.groupby('movie_id').size()[lambda x: x >= movie_threshold].index)]\n",
    "\n",
    "        user_mapping = {id: index for index, id in enumerate(df['user_id'].unique())}\n",
    "        movie_mapping = {id: index for index, id in enumerate(df['movie_id'].unique())}\n",
    "        reverse_movie_mapping = {index: id for id, index in movie_mapping.items()}\n",
    "\n",
    "        df['user_idx'] = df['user_id'].map(user_mapping)\n",
    "        df['movie_idx'] = df['movie_id'].map(movie_mapping)\n",
    "        df['rating_val'] = 1  # Set all interactions to 1 for implicit feedback\n",
    "\n",
    "        sparse_matrix = csr_matrix(\n",
    "            (df['rating_val'], (df['user_idx'], df['movie_idx'])),\n",
    "            shape=(df['user_idx'].max() + 1, df['movie_idx'].max() + 1)\n",
    "        )\n",
    "\n",
    "        algo = BayesianPersonalizedRanking(factors=num_factors, learning_rate=learning_rate,\n",
    "                                           regularization=regularization, random_state=42)\n",
    "        algo.fit(sparse_matrix.T)\n",
    "\n",
    "        bpr_data = (user_mapping, movie_mapping, reverse_movie_mapping, sparse_matrix)\n",
    "\n",
    "    else:\n",
    "        # Surprise model fallback for SVD or NMF\n",
    "        from surprise import SVD, NMF, Dataset, Reader\n",
    "        reader = Reader(rating_scale=(1, 10))\n",
    "        data = Dataset.load_from_df(df[[\"user_id\", \"movie_id\", \"rating_val\"]], reader)\n",
    "        algo = NMF(random_state=42) if model == 'NMF' else SVD(random_state=42)\n",
    "        trainingSet = data.build_full_trainset()\n",
    "        algo.fit(trainingSet)\n",
    "        bpr_data = None\n",
    "\n",
    "    user_watched_list = [x['movie_id'] for x in user_data_filtered]\n",
    "\n",
    "    return algo, user_watched_list, bpr_data\n",
    "\n",
    "def get_page_count(username):\n",
    "    url = \"https://letterboxd.com/{}/films/by/date\"\n",
    "    r = requests.get(url.format(username))\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    body = soup.find(\"body\")\n",
    "\n",
    "    try:\n",
    "        if \"error\" in body[\"class\"]:\n",
    "            return -1, None\n",
    "    except KeyError:\n",
    "        print(body)\n",
    "        return -1, None\n",
    "\n",
    "    try:\n",
    "        page_link = soup.findAll(\"li\", attrs={\"class\", \"paginate-page\"})[-1]\n",
    "        num_pages = int(page_link.find(\"a\").text.replace(\",\", \"\"))\n",
    "        display_name = (\n",
    "            body.find(\"section\", attrs={\"class\": \"profile-header\"})\n",
    "            .find(\"h1\", attrs={\"class\": \"title-3\"})\n",
    "            .text.strip()\n",
    "        )\n",
    "    except IndexError:\n",
    "        num_pages = 1\n",
    "        display_name = None\n",
    "\n",
    "    return num_pages, display_name\n",
    "\n",
    "async def get_user_ratings(\n",
    "    username,\n",
    "    db_cursor=None,\n",
    "    mongo_db=None,\n",
    "    store_in_db=True,\n",
    "    num_pages=None,\n",
    "    return_unrated=False,\n",
    "):\n",
    "    url = \"https://letterboxd.com/{}/films/by/date/page/{}/\"\n",
    "\n",
    "    if not num_pages:\n",
    "        user = db_cursor.find_one({\"username\": username})\n",
    "        num_pages = user[\"recent_page_count\"]\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        tasks = [\n",
    "            asyncio.ensure_future(\n",
    "                fetch(url.format(username, i + 1), session, {\"username\": username})\n",
    "            )\n",
    "            for i in range(num_pages)\n",
    "        ]\n",
    "        scrape_responses = await asyncio.gather(*tasks)\n",
    "        scrape_responses = [x for x in scrape_responses if x]\n",
    "\n",
    "    tasks = [\n",
    "        asyncio.ensure_future(\n",
    "            generate_ratings_operations(\n",
    "                response, send_to_db=store_in_db, return_unrated=return_unrated\n",
    "            )\n",
    "        )\n",
    "        for response in scrape_responses\n",
    "    ]\n",
    "    parse_responses = await asyncio.gather(*tasks)\n",
    "\n",
    "    if not store_in_db:\n",
    "        # Flatten the raw data into a single list\n",
    "        parse_responses = list(\n",
    "            chain.from_iterable(list(chain.from_iterable(parse_responses)))\n",
    "        )\n",
    "        return parse_responses\n",
    "\n",
    "    upsert_ratings_operations = []\n",
    "    upsert_movies_operations = []\n",
    "    for response in parse_responses:\n",
    "        upsert_ratings_operations += response[0]\n",
    "        upsert_movies_operations += response[1]\n",
    "\n",
    "    return upsert_ratings_operations, upsert_movies_operations\n",
    "\n",
    "async def get_user_data(username, data_opt_in=False):\n",
    "    num_pages, display_name = get_page_count(username)\n",
    "\n",
    "    if num_pages == -1:\n",
    "        return [], \"user_not_found\"\n",
    "\n",
    "    user_ratings = await get_user_ratings(\n",
    "        username,\n",
    "        db_cursor=None,\n",
    "        mongo_db=None,\n",
    "        store_in_db=False,  # Ensure we get raw data\n",
    "        num_pages=num_pages,\n",
    "        return_unrated=True,\n",
    "    )\n",
    "\n",
    "    # Filter out items where no rating or like is present\n",
    "    user_ratings = [x for x in user_ratings if x[\"rating_val\"] >= 0 or x[\"rating_val\"] == -1]\n",
    "\n",
    "    if data_opt_in:\n",
    "        send_to_db(username, display_name, user_ratings=user_ratings)\n",
    "\n",
    "    return user_ratings, \"success\"\n",
    "\n",
    "df = training_df.copy()\n",
    "\n",
    "\"\"\"\n",
    "user_data, status = await get_user_data('geraldne')\n",
    "\n",
    "if status == \"success\":\n",
    "    user_data_train, user_data_test = train_test_split(\n",
    "                user_data, test_size=0.2, random_state=42, stratify=[val == -1 for val in rating_vals])\n",
    "    algo, user_watched_list, bpr_data = build_model(df, user_data_train, model='BPR')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c1b273",
   "metadata": {
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1732735037154,
     "user": {
      "displayName": "Sierra Eva Martinez-Kratz",
      "userId": "11773033365985257755"
     },
     "user_tz": 300
    },
    "id": "84c1b273"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    from .db_config import config\n",
    "except ImportError:\n",
    "    config = None\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=20):\n",
    "    top_n = [(iid, est) for uid, iid, true_r, est, _ in predictions]\n",
    "    top_n.sort(key=lambda x: (x[1], random.random()), reverse=True)\n",
    "\n",
    "    return top_n[:n]\n",
    "\n",
    "\n",
    "def run_model(username, algo, user_watched_list, user_data_test, threshold_movie_list, bpr_data=None, num_recommendations=100):\n",
    "\n",
    "    user_watched_test = [(x['movie_id'], x['rating_val']) for x in user_data_test]\n",
    "\n",
    "    unwatched_movies = [x for x in threshold_movie_list if x not in user_watched_list]\n",
    "\n",
    "    if bpr_data:\n",
    "        user_mapping, movie_mapping, reverse_movie_mapping, sparse_matrix = bpr_data\n",
    "        if username in user_mapping:\n",
    "            user_idx = user_mapping[username]\n",
    "            if 0 <= user_idx < sparse_matrix.shape[0]:\n",
    "                user_items = sparse_matrix[user_idx]\n",
    "                recommendations = algo.recommend(user_idx, user_items, N=num_recommendations, filter_already_liked_items=False)\n",
    "                item_indices, scores = recommendations\n",
    "                top_n = [(reverse_movie_mapping[item_idx], score) for item_idx, score in zip(item_indices, scores) if item_idx in reverse_movie_mapping]\n",
    "                top_n = sorted(top_n, key=lambda x: x[1], reverse=True)\n",
    "            else:\n",
    "                raise IndexError(f\"user_idx {user_idx} out of bounds for sparse_matrix with shape {sparse_matrix.shape}.\")\n",
    "        else:\n",
    "            raise ValueError(f\"username '{username}' not found in user_mapping.\")\n",
    "    else:\n",
    "        predictions = algo.test([(username, x, 0) for x in unwatched_movies])\n",
    "        top_n = get_top_n(predictions, num_recommendations)\n",
    "\n",
    "    movie_fields = [\"image_url\", \"movie_id\", \"movie_title\", \"year_released\", \"genres\", \"original_language\", \"popularity\", \"runtime\", \"release_date\"]\n",
    "    metrics = compute_metrics(top_n, user_watched_test)\n",
    "    movie_ids = [x[0] for x in top_n]\n",
    "    filtered_movies = movies[movies[\"movie_id\"].isin(movie_ids)]\n",
    "    movie_data = {\n",
    "        row[\"movie_id\"]: {k: row[k] for k in filtered_movies.columns if k in movie_fields}\n",
    "        for _, row in filtered_movies.iterrows()\n",
    "    }\n",
    "\n",
    "    return_object = [\n",
    "        {\"movie_id\": x[0], \"predicted_rating\": round(x[1], 3), \"movie_data\": movie_data[x[0]]}\n",
    "        for x in top_n if x[0] in movie_data.keys()\n",
    "    ]\n",
    "    return return_object, metrics\n",
    "\n",
    "#recs, metrics = run_model('geraldne', algo, user_watched_list, user_data_test, threshold_movie_list, bpr_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65655996",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65655996",
    "outputId": "2a8886d0-4b9b-4fee-fe28-92b570f9a02c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data loaded from user_data_test.pkl\n",
      "Fetched data for 29 users.\n",
      "Error splitting data for user 'jordyn28': The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "Error splitting data for user 'browsehorror': The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "Error processing user jordyn28: cannot unpack non-iterable NoneType object\n",
      "Error processing user browsehorror: cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.026278257369995117 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce43658f48f147e9b31c1676c7bd4a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.03454017639160156 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70744850561249e0b1dba69242705565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.13366127014160156 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.1282670497894287 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.24408721923828125 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.02431011199951172 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0397191047668457 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.04052996635437012 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.013457298278808594 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.046823740005493164 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.012681961059570312 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0500340461730957 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdb8b1d981049f0bb010000b88b3cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0684b2033d47471e8221be613295b803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ef8f02240e45e2af108e70449ff95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf81d81256143f9af85b7c5613d2d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1d8b4d9d76418cbf9164d234c06f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd4bc73f0db407193e465ba332cf68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19357d461d6a4cacb7b14b71bfa76216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4663ca09644e3cbc60c91e70896454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1a627cb31d405d85fa3b473749af39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5b5014159b4c958131206fb6e4861b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.006396770477294922 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0060651302337646484 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a813c83bc5b54e9d941146c4dc6b513b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801ff6c564114ce587d10d6bb86a97ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error splitting data for user 'melodramafilms': The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "Error processing user melodramafilms: cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.01698613166809082 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44aead7e56d94183b2ab1427e828b593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error splitting data for user 'frozen2013': The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "Error processing user frozen2013: cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0016529560089111328 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ac878605f94b4c85a3638e1a9f7dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.04878091812133789 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341a4cf10a364578afe77408af3968cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.02075982093811035 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc29061f40cd4a09afccbb6e933ff3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9670a32e4294eba96e1c22d970b386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74862b9db0aa406aadc7e3b45780b264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.011779069900512695 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.020420074462890625 seconds\n",
      "  warnings.warn(\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.014415740966796875 seconds\n",
      "  warnings.warn(\n",
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.006858110427856445 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9ef744a6f14d518738fd81b13f8e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff535d2034840b0a062141a9c8fae4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0024890899658203125 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff92959d37764ed3a7490747fb9b0dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.014675140380859375 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839f555406d847bd9f85e9eb6752a2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sierramartinez-kratz/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0060231685638427734 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba26e45148f2abecdd796a298d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async def fetch_all_user_data(users_to_test, get_user_data):\n",
    "    \"\"\"\n",
    "    Fetch data for all users asynchronously and store it in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        users_to_test (list): List of usernames to fetch data for.\n",
    "        get_user_data (function): Asynchronous function to fetch user data.\n",
    "\n",
    "    Returns:\n",
    "        user_data_dict (dict): Dictionary with username as key and user data as value.\n",
    "    \"\"\"\n",
    "    user_data_dict = {}\n",
    "\n",
    "    async def fetch_user(username):\n",
    "        \"\"\"Fetch data for a single user.\"\"\"\n",
    "        print(f\"Fetching data for user: {username}\")\n",
    "        user_data, status = await get_user_data(username)\n",
    "        if status and user_data:\n",
    "            user_data_dict[username] = user_data\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for user: {username}. Skipping.\")\n",
    "\n",
    "    # Create a list of tasks to fetch data for all users concurrently\n",
    "    tasks = [fetch_user(username) for username in users_to_test]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "    return user_data_dict\n",
    "\n",
    "def save_user_data(user_data_dict, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(user_data_dict, f)\n",
    "    print(f\"User data saved to {filename}\")\n",
    "\n",
    "def load_user_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        user_data_dict = pickle.load(f)\n",
    "    print(f\"User data loaded from {filename}\")\n",
    "    return user_data_dict\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "\n",
    "def evaluate_models(users_to_test, user_data_dict, df, threshold_movie_list):\n",
    "    results = []\n",
    "    recommendations = {}\n",
    "\n",
    "    def process_user(username):\n",
    "        user_results = []\n",
    "        user_recommendations = {}\n",
    "\n",
    "        if username not in user_data_dict:\n",
    "            print(f\"No data available for user: {username}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Extract user-specific data and split into train/test\n",
    "            user_data = user_data_dict[username]\n",
    "            rating_vals = [x['rating_val'] for x in user_data]\n",
    "            user_data_train, user_data_test = train_test_split(\n",
    "                user_data, test_size=0.2, random_state=42, stratify=[val == -1 for val in rating_vals]\n",
    "            )\n",
    "            user_watched_test = [(x['movie_id'], x['rating_val']) for x in user_data_test]\n",
    "\n",
    "            # Initialize the user's entry in recommendations\n",
    "            user_recommendations = {}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error splitting data for user '{username}': {e}\")\n",
    "            return None\n",
    "\n",
    "        # Train and evaluate each model\n",
    "        for model_name in ['SVD', 'NMF', 'BPR']:\n",
    "            try:\n",
    "                # Build the model and retrieve necessary data\n",
    "                algo, user_watched_list, bpr_data = build_model(df, user_data_train, model=model_name)\n",
    "\n",
    "                # Run the model and retrieve recommendations and metrics\n",
    "                recs, metrics = run_model(\n",
    "                    username,\n",
    "                    algo,\n",
    "                    user_watched_list,\n",
    "                    user_data_test,\n",
    "                    threshold_movie_list,\n",
    "                    bpr_data,\n",
    "                    num_recommendations=50\n",
    "                )\n",
    "\n",
    "                # Add user and model information to metrics\n",
    "                metrics['model'] = model_name\n",
    "                metrics['user'] = username\n",
    "                user_results.append(metrics)\n",
    "\n",
    "                # Store recommendations\n",
    "                user_recommendations[model_name] = recs\n",
    "\n",
    "            except ValueError as ve:\n",
    "                print(f\"Skipping user '{username}' for model '{model_name}' due to ValueError: {ve}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error for user '{username}' and model '{model_name}': {e}\")\n",
    "\n",
    "        return user_results, user_recommendations\n",
    "\n",
    "    # Parallelize user processing\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(process_user, username): username for username in users_to_test}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            username = futures[future]\n",
    "            try:\n",
    "                user_results, user_recommendations = future.result()\n",
    "                if user_results:\n",
    "                    results.extend(user_results)\n",
    "                if user_recommendations:\n",
    "                    recommendations[username] = user_recommendations\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing user {username}: {e}\")\n",
    "\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    return metrics_df, recommendations\n",
    "\n",
    "async def main(users_to_test, df, get_user_data, threshold_movie_list, data_file=None):\n",
    "    \"\"\"\n",
    "    Main function to fetch data, save/load it, and evaluate models.\n",
    "\n",
    "    Parameters:\n",
    "        users_to_test (list): List of usernames to evaluate.\n",
    "        df (pd.DataFrame): Ratings DataFrame.\n",
    "        get_user_data (function): Asynchronous function to fetch user data.\n",
    "        threshold_movie_list (list): List of movies to recommend from.\n",
    "        data_file (str): Path to save/load user data.\n",
    "\n",
    "    Returns:\n",
    "        metrics_df (pd.DataFrame): DataFrame containing metrics for each model and user.\n",
    "        recommendations (dict): Nested dictionary with recommendations for each user and model.\n",
    "    \"\"\"\n",
    "    # Check if data_file exists\n",
    "    if data_file:\n",
    "        try:\n",
    "            # Try loading user data from the file\n",
    "            user_data_dict = load_user_data(data_file)\n",
    "        except FileNotFoundError:\n",
    "            # If file not found, fetch and save data\n",
    "            print(f\"{data_file} not found. Fetching user data.\")\n",
    "            user_data_dict = await fetch_all_user_data(users_to_test, get_user_data)\n",
    "            save_user_data(user_data_dict, data_file)\n",
    "    else:\n",
    "        # If no file provided, fetch user data\n",
    "        user_data_dict = await fetch_all_user_data(users_to_test, get_user_data)\n",
    "\n",
    "    print(f\"Fetched data for {len(user_data_dict)} users.\")\n",
    "\n",
    "    # Evaluate models using the fetched data\n",
    "    metrics_df, recommendations = evaluate_models(users_to_test, user_data_dict, df, threshold_movie_list)\n",
    "    return metrics_df, recommendations\n",
    "\n",
    "# List of users you want to evaluate\n",
    "usernames = pd.read_csv('letterboxd_users.csv')\n",
    "users_to_test = list(usernames['username'])\n",
    "\n",
    "# File to save/load user data\n",
    "data_file = 'user_data_test.pkl'\n",
    "\n",
    "# Run the main function\n",
    "metrics_df, recommendations = asyncio.run(main(users_to_test, df, get_user_data, threshold_movie_list, data_file=data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875dc176",
   "metadata": {
    "id": "875dc176",
    "outputId": "3f308f0e-2391-43d4-df96-a67cfe7c8215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       precision_at_k  mean_reciprocal_rank      ndcg\n",
      "model                                                \n",
      "BPR             0.020              0.038688  0.010844\n",
      "NMF             0.004              0.040000  0.002287\n",
      "SVD             0.068              0.157937  0.045061\n"
     ]
    }
   ],
   "source": [
    "summary = metrics_df.groupby('model').mean(numeric_only=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "006f99ed",
   "metadata": {
    "id": "006f99ed"
   },
   "outputs": [],
   "source": [
    "#with open(\"recommendations.pkl\", \"wb\") as file:\n",
    "    #pickle.dump(recommendations, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ea64a34",
   "metadata": {
    "id": "1ea64a34"
   },
   "outputs": [],
   "source": [
    "#metrics_df.to_csv('metrics_results_ranked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33e690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
